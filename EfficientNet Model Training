{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":81200,"sourceType":"modelInstanceVersion","modelInstanceId":68237,"modelId":93416},{"sourceId":81381,"sourceType":"modelInstanceVersion","modelInstanceId":68390,"modelId":93570},{"sourceId":84733,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":71178,"modelId":96173},{"sourceId":85268,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":71178,"modelId":96173}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-29T14:26:00.754506Z","iopub.execute_input":"2024-07-29T14:26:00.754850Z","iopub.status.idle":"2024-07-29T14:26:01.725487Z","shell.execute_reply.started":"2024-07-29T14:26:00.754820Z","shell.execute_reply":"2024-07-29T14:26:01.724542Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler, Subset\nfrom torchvision import transforms\nimport pandas as pd\nimport h5py\nimport torch\nimport torchvision\nfrom torch.optim.lr_scheduler import StepLR\nimport lightgbm as lgb\nfrom PIL import Image\nfrom io import BytesIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score\nfrom sklearn.metrics import ConfusionMatrixDisplay, f1_score\nimport re\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:28:19.907723Z","iopub.execute_input":"2024-07-29T14:28:19.908564Z","iopub.status.idle":"2024-07-29T14:28:28.495397Z","shell.execute_reply.started":"2024-07-29T14:28:19.908518Z","shell.execute_reply":"2024-07-29T14:28:28.494533Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# for model in dir(torchvision.models):\n#     print(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:28:28.496767Z","iopub.execute_input":"2024-07-29T14:28:28.497398Z","iopub.status.idle":"2024-07-29T14:28:28.501306Z","shell.execute_reply.started":"2024-07-29T14:28:28.497370Z","shell.execute_reply":"2024-07-29T14:28:28.500353Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:04.897835Z","iopub.execute_input":"2024-07-29T14:30:04.898219Z","iopub.status.idle":"2024-07-29T14:30:04.938019Z","shell.execute_reply.started":"2024-07-29T14:30:04.898187Z","shell.execute_reply":"2024-07-29T14:30:04.937056Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def score(solution: np.ndarray, submission: np.ndarray, min_tpr: float=0.80) -> float:\n    v_gt = abs(solution-1)\n    v_pred = np.array([1.0 - x for x in submission])\n    max_fpr = abs(1-min_tpr)\n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    \n    return(partial_auc)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:05.550513Z","iopub.execute_input":"2024-07-29T14:30:05.551102Z","iopub.status.idle":"2024-07-29T14:30:05.557295Z","shell.execute_reply.started":"2024-07-29T14:30:05.551068Z","shell.execute_reply":"2024-07-29T14:30:05.556335Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def pauc_80(preds, data):\n    score_value = score(data.get_label(), preds, min_tpr=0.8)\n    return 'pauc_80', score_value, True","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:06.218534Z","iopub.execute_input":"2024-07-29T14:30:06.219151Z","iopub.status.idle":"2024-07-29T14:30:06.223342Z","shell.execute_reply.started":"2024-07-29T14:30:06.219118Z","shell.execute_reply":"2024-07-29T14:30:06.222547Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ISICDataset(Dataset):\n    def __init__(self, hdf5_file, isic_ids, metadata, targets=None, transform=None):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.targets = targets\n        self.transform = transform\n        self.metadata = metadata\n        \n    def __len__(self):\n        return len(self.isic_ids)\n    \n    def __getitem__(self, idx):\n        isic_id = self.isic_ids[idx]\n        image = Image.open(BytesIO(self.hdf5_file[isic_id][()])) # convert byte array to PIL image\n        meta = torch.tensor(self.metadata.iloc[idx].tolist(), dtype=torch.float32)\n        if self.transform:\n            image = self.transform(image)\n        if self.targets is not None:\n            target = self.targets[idx]\n            return image, meta, target\n        else:\n            return image, meta\n        \n    def get_target(self, idx):\n        return int(self.targets[idx])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:06.722681Z","iopub.execute_input":"2024-07-29T14:30:06.723015Z","iopub.status.idle":"2024-07-29T14:30:06.731388Z","shell.execute_reply.started":"2024-07-29T14:30:06.722987Z","shell.execute_reply":"2024-07-29T14:30:06.730355Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"num_cols = [\n    'age_approx',\n    'clin_size_long_diam_mm',\n    'tbp_lv_A', 'tbp_lv_Aext',\n    'tbp_lv_B', 'tbp_lv_Bext',\n    'tbp_lv_C', 'tbp_lv_Cext', \n    'tbp_lv_H', 'tbp_lv_Hext',\n    'tbp_lv_L', 'tbp_lv_Lext',\n    'tbp_lv_areaMM2',\n    'tbp_lv_area_perim_ratio',\n    'tbp_lv_color_std_mean',\n    'tbp_lv_deltaA', 'tbp_lv_deltaB',\n    'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n    'tbp_lv_deltaLBnorm',\n    'tbp_lv_eccentricity',\n    'tbp_lv_minorAxisMM',\n    'tbp_lv_nevi_confidence',\n    'tbp_lv_norm_border',\n    'tbp_lv_norm_color', 'tbp_lv_perimeterMM',\n    'tbp_lv_radial_color_std_max',\n    'tbp_lv_stdL', 'tbp_lv_stdLExt',\n    'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z'\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'image_type', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple']","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:07.211439Z","iopub.execute_input":"2024-07-29T14:30:07.212154Z","iopub.status.idle":"2024-07-29T14:30:07.217764Z","shell.execute_reply.started":"2024-07-29T14:30:07.212104Z","shell.execute_reply":"2024-07-29T14:30:07.216843Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/isic-2024-challenge/\"\ntrain_path = data_path + \"train-metadata.csv\"\ntest_path = data_path + \"test-metadata.csv\"\n\ntrain_meta = pd.read_csv(train_path)\ntest_meta = pd.read_csv(test_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:07.745196Z","iopub.execute_input":"2024-07-29T14:30:07.745793Z","iopub.status.idle":"2024-07-29T14:30:15.120892Z","shell.execute_reply.started":"2024-07-29T14:30:07.745749Z","shell.execute_reply":"2024-07-29T14:30:15.119929Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2499741512.py:5: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_meta = pd.read_csv(train_path)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_X = train_meta.filter(num_cols + cat_cols)\ntest_X = test_meta.filter(num_cols + cat_cols)\ntrain_X = pd.get_dummies(train_X, columns=cat_cols)\ntest_X = pd.get_dummies(test_X, columns=cat_cols)\ntrain_X = train_X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\ntest_X = test_X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\ntrain_X, test_X = train_X.align(test_X, join='outer', axis=1, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.122459Z","iopub.execute_input":"2024-07-29T14:30:15.122762Z","iopub.status.idle":"2024-07-29T14:30:15.698487Z","shell.execute_reply.started":"2024-07-29T14:30:15.122736Z","shell.execute_reply":"2024-07-29T14:30:15.697495Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(60),\n    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n    transforms.RandomResizedCrop(224),\n#     transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet statistics\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.700013Z","iopub.execute_input":"2024-07-29T14:30:15.700377Z","iopub.status.idle":"2024-07-29T14:30:15.707153Z","shell.execute_reply.started":"2024-07-29T14:30:15.700336Z","shell.execute_reply":"2024-07-29T14:30:15.706042Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"isic_ids = train_meta[\"isic_id\"].values\ntargets = train_meta[\"target\"].values\ntrain_hdf5 = h5py.File(data_path + \"/train-image.hdf5\", 'r')\n\ntest_isic_ids = test_meta[\"isic_id\"].values\ntest_hdf5 = h5py.File(data_path + \"/test-image.hdf5\", \"r\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.709751Z","iopub.execute_input":"2024-07-29T14:30:15.710114Z","iopub.status.idle":"2024-07-29T14:30:15.729535Z","shell.execute_reply.started":"2024-07-29T14:30:15.710072Z","shell.execute_reply":"2024-07-29T14:30:15.728630Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_dataset = ISICDataset(train_hdf5, isic_ids, train_X, targets, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.730699Z","iopub.execute_input":"2024-07-29T14:30:15.731034Z","iopub.status.idle":"2024-07-29T14:30:15.743610Z","shell.execute_reply.started":"2024-07-29T14:30:15.731002Z","shell.execute_reply":"2024-07-29T14:30:15.742730Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_dataset = ISICDataset(test_hdf5, test_isic_ids, test_X, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.744706Z","iopub.execute_input":"2024-07-29T14:30:15.744997Z","iopub.status.idle":"2024-07-29T14:30:15.753523Z","shell.execute_reply.started":"2024-07-29T14:30:15.744973Z","shell.execute_reply":"2024-07-29T14:30:15.752641Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\ntest_size = len(train_dataset) - train_size\n\ntrain_set, val_set = random_split(train_dataset, [train_size, test_size])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.754598Z","iopub.execute_input":"2024-07-29T14:30:15.754878Z","iopub.status.idle":"2024-07-29T14:30:15.815915Z","shell.execute_reply.started":"2024-07-29T14:30:15.754855Z","shell.execute_reply":"2024-07-29T14:30:15.814991Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_labels = [train_set.dataset.get_target(i) for i in train_set.indices]\n\ntrain_class_counts = {}\nfor label in train_labels:\n    if label in train_class_counts:\n        train_class_counts[label] += 1\n    else:\n        train_class_counts[label] = 1\ntrain_total = sum(train_class_counts.values())\nclass_weights = [train_total / train_class_counts[count]  for count in train_class_counts]\nprint(train_class_counts)\n\nsample_weights = torch.tensor([class_weights[train_set.dataset.get_target(i)] for i in train_set.indices])\nrandom_oversampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(train_set), replacement=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:15.817031Z","iopub.execute_input":"2024-07-29T14:30:15.817382Z","iopub.status.idle":"2024-07-29T14:30:16.355280Z","shell.execute_reply.started":"2024-07-29T14:30:15.817350Z","shell.execute_reply":"2024-07-29T14:30:16.354435Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{0: 320520, 1: 327}\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nprint(f'Number of CPU cores: {os.cpu_count()}')","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:16.357497Z","iopub.execute_input":"2024-07-29T14:30:16.357783Z","iopub.status.idle":"2024-07-29T14:30:16.362640Z","shell.execute_reply.started":"2024-07-29T14:30:16.357758Z","shell.execute_reply":"2024-07-29T14:30:16.361760Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Number of CPU cores: 4\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=64, sampler=random_oversampler, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_set, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:18.798273Z","iopub.execute_input":"2024-07-29T14:30:18.798621Z","iopub.status.idle":"2024-07-29T14:30:18.803878Z","shell.execute_reply.started":"2024-07-29T14:30:18.798592Z","shell.execute_reply":"2024-07-29T14:30:18.802912Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:19.414304Z","iopub.execute_input":"2024-07-29T14:30:19.414647Z","iopub.status.idle":"2024-07-29T14:30:19.419027Z","shell.execute_reply.started":"2024-07-29T14:30:19.414619Z","shell.execute_reply":"2024-07-29T14:30:19.418147Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.efficientnet_b0()\n# model.load_state_dict(torch.load())\nmodel.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\nmodel.classifier.append(torch.nn.Softmax(dim=1))\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:19.904251Z","iopub.execute_input":"2024-07-29T14:30:19.904594Z","iopub.status.idle":"2024-07-29T14:30:20.194726Z","shell.execute_reply.started":"2024-07-29T14:30:19.904567Z","shell.execute_reply":"2024-07-29T14:30:20.193941Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_and_validate(model, train_loader, val_loader, optimizer, scheduler, loss_func, device, epochs=10, patience=10, save_path='best_model.pth'):\n    # Move model to the device being used\n    model = model.to(device)\n    \n    # To store the training and validation loss for plotting or analysis\n    history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': [], 'train_f1': [], 'val_f1': []}\n\n    best_val_loss = float('inf')\n    patience_counter = 0  # Counter for the early stopping\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        correct_train = 0\n        total_train = 0\n        train_preds, train_targets = [], []\n\n        for images, metas, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_func(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs.data, 1)\n            correct_train += (predicted == labels).sum().item()\n            total_train += labels.size(0)\n\n            train_preds.extend(predicted.cpu().numpy())\n            train_targets.extend(labels.cpu().numpy())\n\n        train_accuracy = 100 * correct_train / total_train\n        train_f1 = f1_score(train_targets, train_preds, average='weighted')\n        train_pauc = score(np.array(train_targets), train_preds)\n        train_precision = precision_score(train_targets, train_preds)\n        train_recall = recall_score(train_targets, train_preds)\n        \n        epoch_train_loss = train_loss / len(train_loader.dataset)\n        history['train_loss'].append(epoch_train_loss)\n        history['train_accuracy'].append(train_accuracy)\n        history['train_f1'].append(train_f1)\n\n        # Scheduler step (commonly after training step, can be adjusted as per scheduler type)\n        scheduler.step()\n\n        model.eval()\n        val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n        val_preds, val_targets = [], []\n\n        with torch.no_grad():\n            for images, metas, labels in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\"):\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = loss_func(outputs, labels)\n\n                val_loss += loss.item() * images.size(0)\n                _, predicted = torch.max(outputs.data, 1)\n                correct_val += (predicted == labels).sum().item()\n                total_val += labels.size(0)\n\n                val_preds.extend(predicted.cpu().numpy())\n                val_targets.extend(labels.cpu().numpy())\n\n        val_accuracy = 100 * correct_val / total_val\n        val_f1 = f1_score(val_targets, val_preds, average='weighted')\n        val_pauc = score(np.array(val_targets), val_preds)\n        val_precision = precision_score(val_targets, val_preds)\n        val_recall = recall_score(val_targets, val_preds)\n        \n        epoch_val_loss = val_loss / len(val_loader.dataset)\n        history['val_loss'].append(epoch_val_loss)\n        history['val_accuracy'].append(val_accuracy)\n        history['val_f1'].append(val_f1)\n\n        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Validation F1: {val_f1:.4f}')\n        print(f'Train pAUC: {train_pauc}, Train Precision: {train_precision}, Train Recall: {train_recall}')\n        print(f'Validation pAUC: {val_pauc}, Validation Precision: {val_precision}, Validation Recall: {val_recall}')\n        \n        # Check for improvement in validation loss\n        if epoch_val_loss < best_val_loss:\n            best_val_loss = epoch_val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), save_path)  # Save the best model\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Stopping early after {epoch + 1} epochs due to no improvement in validation loss.\")\n                model.load_state_dict(torch.load(save_path))  # Load the best model weights\n                break\n                \n        checkpoint_path = f'model_checkpoint_epoch_{epoch + 1}.pth'\n        torch.save(model.state_dict(), checkpoint_path)\n        print(f'Saved checkpoint: {checkpoint_path}')\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:20.555796Z","iopub.execute_input":"2024-07-29T14:30:20.556620Z","iopub.status.idle":"2024-07-29T14:30:20.582345Z","shell.execute_reply.started":"2024-07-29T14:30:20.556588Z","shell.execute_reply":"2024-07-29T14:30:20.581437Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters())\nscheduler = StepLR(optimizer, step_size=7, gamma=0.1)\nloss_func = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T14:30:21.066184Z","iopub.execute_input":"2024-07-29T14:30:21.066557Z","iopub.status.idle":"2024-07-29T14:30:21.075154Z","shell.execute_reply.started":"2024-07-29T14:30:21.066527Z","shell.execute_reply":"2024-07-29T14:30:21.073600Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# history = train_and_validate(model, train_loader, val_loader, optimizer, scheduler, loss_func, device)\n\n\n# load best model for submission\nmodel.load_state_dict(torch.load('/kaggle/input/efficientnet-isic/pytorch/default/2/model_checkpoint_epoch_4.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-07-29T18:00:42.788486Z","iopub.execute_input":"2024-07-29T18:00:42.789280Z","iopub.status.idle":"2024-07-29T18:00:43.164479Z","shell.execute_reply.started":"2024-07-29T18:00:42.789243Z","shell.execute_reply":"2024-07-29T18:00:43.163183Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\n\npredictions = []\nwith torch.no_grad():\n    for images, metas in test_loader:\n        images, metas = images.to(device), metas\n        outputs = model(images).cpu()\n        softmax = torch.nn.functional.softmax(outputs.data, dim=1)\n        predicted = softmax[:, 1]\n        predictions.extend(predicted.numpy())","metadata":{"execution":{"iopub.status.busy":"2024-07-29T18:00:44.914657Z","iopub.execute_input":"2024-07-29T18:00:44.915092Z","iopub.status.idle":"2024-07-29T18:00:45.002479Z","shell.execute_reply.started":"2024-07-29T18:00:44.915056Z","shell.execute_reply":"2024-07-29T18:00:45.001644Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.DataFrame({'isic_id':test_isic_ids, 'target':predictions})\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T18:00:46.755663Z","iopub.execute_input":"2024-07-29T18:00:46.756015Z","iopub.status.idle":"2024-07-29T18:00:46.762382Z","shell.execute_reply.started":"2024-07-29T18:00:46.755984Z","shell.execute_reply":"2024-07-29T18:00:46.761187Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2024-07-29T18:00:47.311088Z","iopub.execute_input":"2024-07-29T18:00:47.311747Z","iopub.status.idle":"2024-07-29T18:00:47.326013Z","shell.execute_reply.started":"2024-07-29T18:00:47.311716Z","shell.execute_reply":"2024-07-29T18:00:47.325121Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"        isic_id    target\n0  ISIC_0015657  0.268950\n1  ISIC_0015729  0.268941\n2  ISIC_0015740  0.269748","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015657</td>\n      <td>0.268950</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015729</td>\n      <td>0.268941</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015740</td>\n      <td>0.269748</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}